{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QusHvb6qM-7_",
        "bAmCiJs7NbgS",
        "WyEpL00-QN5V",
        "hjDiUCwEODsb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###–ó–∞–¥–∞–Ω–∏–µ 1. –ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ–≥–≥–µ—Ä –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º\n",
        "- –ø—Ä–æ–≤–µ—Ä–∏—Ç—å UnigramTagger, BigramTagger, TrigramTagger –∏ –∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏\n",
        "\n",
        "\n",
        "- –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π —Ç–µ–≥–≥–µ—Ä –∫–∞–∫ –Ω–∞ –∑–∞–Ω—è—Ç–∏–∏, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä—ã, –¥–æ–±–∞–≤–∏—Ç—å –∑–Ω–∞–Ω–∏–µ –Ω–µ —Ç–æ–ª—å–∫–æ –±—É–∫–≤ –Ω–æ –∏ —Å–ª–æ–≤\n",
        "\n",
        "\n",
        "- —Å—Ä–∞–≤–Ω–∏—Ç—å –≤—Å–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã, —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã\n"
      ],
      "metadata": {
        "id": "BukiVJLRu-7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyconll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNvE0HkBr08Y",
        "outputId": "dff8e3bc-1e8e-4625-fa62-b708ed68e95b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyconll\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7U5nm42ZrSzE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# import re\n",
        "import numpy as np\n",
        "# from nltk.corpus import stopwords\n",
        "# from tqdm.notebook import tqdm\n",
        "# from multiprocessing import Pool\n",
        "# import pymorphy2\n",
        "# import matplotlib.pyplot as plt\n",
        "import pyconll\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "setljrz3Fjxs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/sample_data/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-train.conllu\n",
        "!wget -O /content/sample_data/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-dev.conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0n27kxAsFJy",
        "outputId": "21b5bdcb-3fa8-46ac-f89f-9987e2625832"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-26 09:49:39--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17229332 (16M) [text/plain]\n",
            "Saving to: ‚Äò/content/sample_data/ru_syntagrus-ud-train.conllu‚Äô\n",
            "\n",
            "/content/sample_dat 100%[===================>]  16.43M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-10-26 09:49:39 (136 MB/s) - ‚Äò/content/sample_data/ru_syntagrus-ud-train.conllu‚Äô saved [17229332/17229332]\n",
            "\n",
            "--2022-10-26 09:49:40--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 910013 (889K) [text/plain]\n",
            "Saving to: ‚Äò/content/sample_data/ru_syntagrus-ud-dev.conllu‚Äô\n",
            "\n",
            "/content/sample_dat 100%[===================>] 888.68K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-10-26 09:49:40 (18.4 MB/s) - ‚Äò/content/sample_data/ru_syntagrus-ud-dev.conllu‚Äô saved [910013/910013]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_train = pyconll.load_from_file('/content/sample_data/ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('/content/sample_data/ru_syntagrus-ud-dev.conllu')"
      ],
      "metadata": {
        "id": "VUq69c4Nst8p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in full_train[:2]:\n",
        "    for token in sent:\n",
        "        print(token.form, token.upos)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RQKFur9tBaI",
        "outputId": "1be669e8-5a16-44eb-93ad-061fb052d1ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–°–Ω–æ–≤–∞ ADV\n",
            "–ø—Ä–∏–æ–±—Ä–µ–ª VERB\n",
            "–¥–æ–∑—É NOUN\n",
            ", PUNCT\n",
            "\n",
            "–í ADP\n",
            "–∂–µ–Ω—â–∏–Ω–µ NOUN\n",
            "–≤–∞–∂–Ω–∞ ADJ\n",
            "–≤–µ—Ä–Ω–æ—Å—Ç—å NOUN\n",
            ", PUNCT\n",
            "–∞ CCONJ\n",
            "–Ω–µ PART\n",
            "–∫—Ä–∞—Å–æ—Ç–∞ NOUN\n",
            ". PUNCT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdata_train = []\n",
        "for sent in full_train[:]:\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
        "    \n",
        "fdata_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
        "    \n",
        "fdata_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_sent_test.append([token.form for token in sent])"
      ],
      "metadata": {
        "id": "efWIXBQktk-n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdata_train[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bqMjexftt1O",
        "outputId": "83787829-d24a-488b-95f1-2933ac6e58ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('–°–Ω–æ–≤–∞', 'ADV'), ('–ø—Ä–∏–æ–±—Ä–µ–ª', 'VERB'), ('–¥–æ–∑—É', 'NOUN'), (',', 'PUNCT')],\n",
              " [('–í', 'ADP'),\n",
              "  ('–∂–µ–Ω—â–∏–Ω–µ', 'NOUN'),\n",
              "  ('–≤–∞–∂–Ω–∞', 'ADJ'),\n",
              "  ('–≤–µ—Ä–Ω–æ—Å—Ç—å', 'NOUN'),\n",
              "  (',', 'PUNCT'),\n",
              "  ('–∞', 'CCONJ'),\n",
              "  ('–Ω–µ', 'PART'),\n",
              "  ('–∫—Ä–∞—Å–æ—Ç–∞', 'NOUN'),\n",
              "  ('.', 'PUNCT')]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdata_sent_test[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p27va3E4t9QU",
        "outputId": "1a633d45-cc27-4a08-be1c-e1e1ac01bf8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ü§ò', '–•–µ–π', '!'], ['–°—Ç–∞–≤—å', '‚ù§Ô∏è']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taggers_scores = {'unigram_tagger': [],\n",
        "                  'bigram_tagger': [], \n",
        "                  'bi_unigram_tagger': [],\n",
        "                  'trigram_tagger': [],\n",
        "                  'tri_unigram_tagger': [],\n",
        "                  'tri_bi_unigram_tagger': []}"
      ],
      "metadata": {
        "id": "qp84Jicnz8eR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "taggers_scores['unigram_tagger']=unigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "bigram_tagger = BigramTagger(fdata_train)\n",
        "taggers_scores['bigram_tagger']=bigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "bi_unigram_tagger = BigramTagger(fdata_train, backoff=UnigramTagger(fdata_train))\n",
        "taggers_scores['bi_unigram_tagger']=bi_unigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "trigram_tagger = TrigramTagger(fdata_train)\n",
        "taggers_scores['trigram_tagger']=trigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "tri_unigram_tagger = TrigramTagger(fdata_train, backoff=UnigramTagger(fdata_train))\n",
        "taggers_scores['tri_unigram_tagger']=tri_unigram_tagger.evaluate(fdata_test)\n",
        "\n",
        "tri_bi_unigram_tagger = TrigramTagger(fdata_train,\n",
        "                                     backoff=BigramTagger(fdata_train,\n",
        "                                                          backoff=UnigramTagger(fdata_train)))\n",
        "taggers_scores['tri_bi_unigram_tagger']=tri_bi_unigram_tagger.evaluate(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPEdgsWO1HXZ",
        "outputId": "aecb3fa1-56cc-4ad1-f3a4-bfcf730f97f6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(taggers_scores, index=['score']).T.sort_values('score', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "7Wqk7VSm54-D",
        "outputId": "416a980d-1b54-481c-bd9b-045d69c0f890"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          score\n",
              "tri_bi_unigram_tagger  0.686708\n",
              "tri_unigram_tagger     0.686510\n",
              "bi_unigram_tagger      0.685915\n",
              "unigram_tagger         0.683142\n",
              "bigram_tagger          0.135994\n",
              "trigram_tagger         0.096177"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-845e13df-8223-4c37-827f-e029b579624e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tri_bi_unigram_tagger</th>\n",
              "      <td>0.686708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tri_unigram_tagger</th>\n",
              "      <td>0.686510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bi_unigram_tagger</th>\n",
              "      <td>0.685915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unigram_tagger</th>\n",
              "      <td>0.683142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bigram_tagger</th>\n",
              "      <td>0.135994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trigram_tagger</th>\n",
              "      <td>0.096177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-845e13df-8223-4c37-827f-e029b579624e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-845e13df-8223-4c37-827f-e029b579624e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-845e13df-8223-4c37-827f-e029b579624e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in fdata_train[:]:\n",
        "    for tok in sent:\n",
        "        train_tok.append(tok[0])\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "        \n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in fdata_test[:]:\n",
        "    for tok in sent:\n",
        "        test_tok.append(tok[0])\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ],
      "metadata": {
        "id": "OiTvKsZOFrF2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)\n",
        "\n",
        "test_enc_labels = le.transform(test_label)"
      ],
      "metadata": {
        "id": "UROfxgW6F-ns"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {'vectorizer': [],\n",
        "          'f1_score': [],\n",
        "          'accuracy': []}"
      ],
      "metadata": {
        "id": "C2IRJjoJTbcx"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzers = ['word', 'char']\n",
        "n_feats = [1000, 5000, 10000, 15000]\n",
        "vectorizers = [CountVectorizer, TfidfVectorizer, HashingVectorizer]"
      ],
      "metadata": {
        "id": "HxEDl4tEHVSS"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_fit_predict(vec):\n",
        "    X_train = vec.fit_transform(train_tok)\n",
        "    X_test = vec.transform(test_tok)\n",
        "    lr = LogisticRegression(random_state=0, max_iter=100)\n",
        "    lr.fit(X_train, train_enc_labels)\n",
        "    return lr.predict(X_test)"
      ],
      "metadata": {
        "id": "Yv-hM9koWEtD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vect_cls in vectorizers:\n",
        "    for analyzer in analyzers:\n",
        "        if vect_cls == HashingVectorizer:\n",
        "            for n_feat in n_feats:\n",
        "                vectorizer = vect_cls(ngram_range=(1, 3), analyzer=analyzer, n_features=n_feat)\n",
        "                scores['vectorizer'].append(vectorizer)\n",
        "                pred = prepare_fit_predict(vectorizer)\n",
        "                scores['f1_score'].append(f1_score(test_enc_labels, pred, average='weighted'))\n",
        "                scores['accuracy'].append(accuracy_score(test_enc_labels, pred))\n",
        "                \n",
        "        else:\n",
        "            vectorizer = vect_cls(ngram_range=(1, 3), analyzer=analyzer)\n",
        "            scores['vectorizer'].append(vectorizer)\n",
        "            pred = prepare_fit_predict(vectorizer)\n",
        "            scores['f1_score'].append(f1_score(test_enc_labels, pred, average='weighted'))\n",
        "            scores['accuracy'].append(accuracy_score(test_enc_labels, pred)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnAcxltcIga4",
        "outputId": "3f319126-d78c-4879-efc3-3fa1bf09a707"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGVGjj8cZk58",
        "outputId": "7649228e-72ea-4d6b-ace4-744d8f7aa6c9"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(scores).sort_values('f1_score', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "PaDLYxOHYjpe",
        "outputId": "b903dba3-fa06-4e9c-eb1e-26c1d0a78d30"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                  vectorizer  \\\n",
              "1   CountVectorizer(analyzer='char', ngram_range=(1, 3))                       \n",
              "3   TfidfVectorizer(analyzer='char', ngram_range=(1, 3))                       \n",
              "10  HashingVectorizer(analyzer='char', n_features=10000, ngram_range=(1, 3))   \n",
              "11  HashingVectorizer(analyzer='char', n_features=15000, ngram_range=(1, 3))   \n",
              "9   HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 3))    \n",
              "8   HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 3))    \n",
              "0   CountVectorizer(ngram_range=(1, 3))                                        \n",
              "2   TfidfVectorizer(ngram_range=(1, 3))                                        \n",
              "7   HashingVectorizer(n_features=15000, ngram_range=(1, 3))                    \n",
              "6   HashingVectorizer(n_features=10000, ngram_range=(1, 3))                    \n",
              "5   HashingVectorizer(n_features=5000, ngram_range=(1, 3))                     \n",
              "4   HashingVectorizer(n_features=1000, ngram_range=(1, 3))                     \n",
              "\n",
              "    f1_score  accuracy  \n",
              "1   0.860490  0.866977  \n",
              "3   0.837610  0.849544  \n",
              "10  0.826014  0.839045  \n",
              "11  0.824430  0.838847  \n",
              "9   0.820969  0.834093  \n",
              "8   0.783539  0.799525  \n",
              "0   0.543662  0.508023  \n",
              "2   0.536882  0.502377  \n",
              "7   0.524233  0.508716  \n",
              "6   0.516544  0.506537  \n",
              "5   0.505150  0.503269  \n",
              "4   0.435896  0.458994  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9e8bf67-8af5-477d-b89f-36740a212ed1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vectorizer</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CountVectorizer(analyzer='char', ngram_range=(1, 3))</td>\n",
              "      <td>0.860490</td>\n",
              "      <td>0.866977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TfidfVectorizer(analyzer='char', ngram_range=(1, 3))</td>\n",
              "      <td>0.837610</td>\n",
              "      <td>0.849544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=10000, ngram_range=(1, 3))</td>\n",
              "      <td>0.826014</td>\n",
              "      <td>0.839045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=15000, ngram_range=(1, 3))</td>\n",
              "      <td>0.824430</td>\n",
              "      <td>0.838847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 3))</td>\n",
              "      <td>0.820969</td>\n",
              "      <td>0.834093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 3))</td>\n",
              "      <td>0.783539</td>\n",
              "      <td>0.799525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
              "      <td>0.543662</td>\n",
              "      <td>0.508023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
              "      <td>0.536882</td>\n",
              "      <td>0.502377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HashingVectorizer(n_features=15000, ngram_range=(1, 3))</td>\n",
              "      <td>0.524233</td>\n",
              "      <td>0.508716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HashingVectorizer(n_features=10000, ngram_range=(1, 3))</td>\n",
              "      <td>0.516544</td>\n",
              "      <td>0.506537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HashingVectorizer(n_features=5000, ngram_range=(1, 3))</td>\n",
              "      <td>0.505150</td>\n",
              "      <td>0.503269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HashingVectorizer(n_features=1000, ngram_range=(1, 3))</td>\n",
              "      <td>0.435896</td>\n",
              "      <td>0.458994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9e8bf67-8af5-477d-b89f-36740a212ed1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9e8bf67-8af5-477d-b89f-36740a212ed1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9e8bf67-8af5-477d-b89f-36740a212ed1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–ó–∞–¥–∞–Ω–∏–µ 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç NER\n",
        "\n",
        "–î–∞–Ω–Ω—ã–µ –±—Ä–∞—Ç—å –∏–∑ http://www.labinform.ru/pub/named_entities/\n",
        "\n",
        "- –ø—Ä–æ–≤–µ—Ä–∏—Ç—å NER –∏–∑ nltk/spacy/deeppavlov.\n",
        "\n",
        "- –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π NER, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã.\n",
        "\n",
        "    - –ø–µ—Ä–µ–¥–∞—ë–º –≤ —Å–µ—Ç–∫—É —Ç–æ–∫–µ–Ω –∏ –µ–≥–æ —Å–æ—Å–µ–¥–µ–π.\n",
        "\n",
        "    - –ø–µ—Ä–µ–¥–∞—ë–º –≤ —Å–µ—Ç–∫—É —Ç–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω.\n",
        "\n",
        "    - —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç.\n",
        "\n",
        "- —Å—Ä–∞–≤–Ω–∏—Ç—å —Å–≤–æ–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ ‚Äî –≤—ã–≤–µ—Å—Ç–∏ precision/recall/f1_score.\n"
      ],
      "metadata": {
        "id": "F5mFg-uHAwvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOA-3r5wmC2-",
        "outputId": "591399c4-93fc-4c31-ce0e-de3716e99c1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-27 08:41:34--  http://www.labinform.ru/pub/named_entities/collection5.zip\n",
            "Resolving www.labinform.ru (www.labinform.ru)... 95.181.230.181\n",
            "Connecting to www.labinform.ru (www.labinform.ru)|95.181.230.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1899530 (1.8M) [application/zip]\n",
            "Saving to: ‚Äòcollection5.zip‚Äô\n",
            "\n",
            "collection5.zip     100%[===================>]   1.81M   928KB/s    in 2.0s    \n",
            "\n",
            "2022-10-27 08:41:37 (928 KB/s) - ‚Äòcollection5.zip‚Äô saved [1899530/1899530]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/collection5.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "I-D-ytVfm5pA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GljbrDPesOn0",
        "outputId": "896e96be-ec77-4ac7-f177-eb61fc7455ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting corus\n",
            "  Downloading corus-0.9.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83 kB 1.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: corus\n",
            "Successfully installed corus-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZX0zM4LxdOw",
        "outputId": "44d18344-8d48-491e-d603-aa7b0c6a00fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import corus\n",
        "from corus import load_ne5\n",
        "from corus import load_rudrec\n",
        "from razdel import tokenize"
      ],
      "metadata": {
        "id": "tOLgw7xHr-EP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTBhplXnKGO5",
        "outputId": "7f92f013-2168-4b01-82c3-f1ef41a76890"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/Collection5'\n",
        "records = load_ne5(path)"
      ],
      "metadata": {
        "id": "yRN2chHzs7Tx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vbm4RfTtGyb",
        "outputId": "f561415f-ed75-4f90-9f21-bc69c6e0073a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ne5Markup(\n",
              "    id='last_47',\n",
              "    text='\\r\\n–®–∞–Ω—Ü–µ–≤ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–ª —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ –Ω–∞–∑–Ω–∞—á–∏–ª —Å–µ–±–µ –Ω–æ–≤—ã—Ö –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª–µ–π\\r\\n\\r\\n–ì—É–±–µ—Ä–Ω–∞—Ç–æ—Ä –í–∞–ª–µ—Ä–∏–π –®–∞–Ω—Ü–µ–≤ –≤–Ω–µ—Å –∫–∞–¥—Ä–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å–æ—Å—Ç–∞–≤ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏. –ö–∞–∫ —Å–æ–æ–±—â–∞–µ—Ç –®–∞–Ω—Ü–µ–≤ –≤ —Å–≤–æ–µ–º –±–ª–æ–≥–µ, –æ–Ω —É–∂–µ –ø–æ–¥–ø–∏—Å–∞–ª –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –æ–±–ª–∞—Å—Ç–∏.\\r\\n\\r\\n\"–í –Ω—ã–Ω–µ—à–Ω–µ–º –≤–∏–¥–µ, –∑–∞ –Ω–µ–±–æ–ª—å—à–∏–º–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è–º–∏, –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç 3 –≥–æ–¥–∞. –ó–∞ —ç—Ç–æ –≤—Ä–µ–º—è –º–Ω–æ–≥–æ–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø–æ—è–≤–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ –≤—ã–∑–æ–≤—ã - —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ, —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ. –£–±–µ–∂–¥–µ–Ω, —á—Ç–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –¥–æ–ª–∂–Ω–æ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –Ω–∏—Ö, –¥–æ–ª–∂–Ω–æ –∏–¥—Ç–∏ –≤ –Ω–æ–≥—É —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º. –í —Ç–µ—á–µ–Ω–∏–µ –ø–æ–ª—É–≥–æ–¥–∞ —è –ø—Ä–æ–≤–æ–¥–∏–ª –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏. –î–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ —Ü–µ–ª–æ–º –∏ –∫–∞–∂–¥–æ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –±–ª–æ–∫–∞ –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ —Å—á–∏—Ç–∞—é —Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ —Å–ª–µ–¥—É—é—â–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è.\", - –ø–∏—à–µ—Ç –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä.\\r\\n\\r\\n\"–ë–ª–æ–∫ —ç–∫–æ–Ω–æ–º–∏–∫–∏ –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤. –ó–∞–¥–∞—á–∞–º–∏ –í–ª–∞–¥–∏–º–∏—Ä–∞ –ò–≤–∞–Ω–æ–≤–∞ (–≤–∏—Ü–µ-–≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä –ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏) –≤–∏–∂—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ. –° —Ü–µ–ª—å—é —Ä–∞–∑–≤–∏—Ç–∏—è –∏ –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞ —ç–∫–æ–Ω–æ–º–∏–∫–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –±–ª–æ–∫ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–π –∏ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Ä–∞–∑–≤–∏—Ç–∏—è –º–∞–ª–æ–≥–æ –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å—Ç–≤–∞. –ü–æ—Å–ª–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ø—Ä–∏–Ω—è–ª —Ä–µ—à–µ–Ω–∏–µ –æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–∏ –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞, –∫—É—Ä–∏—Ä—É—é—â–µ–≥–æ —ç—Ç–æ—Ç –±–ª–æ–∫, –ï–≤–≥–µ–Ω–∏—è –õ—é–ª–∏–Ω–∞ (–≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –û–û–û \"–õ–£–ö–û–ô–õ-–≠–Ω–µ—Ä–≥–æ—Å–µ—Ç–∏\", —ç–∫—Å-–ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è –ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π). –≠—Ç–æ —Å–∏–ª—å–Ω—ã–π, –≥—Ä–∞–º–æ—Ç–Ω—ã–π –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π —É–ø—Ä–∞–≤–ª–µ–Ω–µ—Ü, –∏–º–µ—é—â–∏–π –±–æ–ª—å—à–æ–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –Ω–∞ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è—Ö –∏ —Ö–æ—Ä–æ—à–æ –∑–Ω–∞—é—â–∏–π –ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫—É—é –æ–±–ª–∞—Å—Ç—å. –í —ç—Ç–æ–º –±–ª–æ–∫–µ —Ç–∞–∫–∂–µ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ —ç–∫–æ–ª–æ–≥–∏–∏ –∏ –ø—Ä–∏—Ä–æ–¥–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤, –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ —Å–µ–ª—å—Å–∫–æ–≥–æ —Ö–æ–∑—è–π—Å—Ç–≤–∞ –∏ –ø—Ä–æ–¥–æ–≤–æ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤, –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ª–µ—Å–Ω–æ–≥–æ —Ö–æ–∑—è–π—Å—Ç–≤–∞ –∏ –∫–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–æ–≥–æ –Ω–∞–¥–∑–æ—Ä–∞\", - —Å–æ–æ–±—â–∞–µ—Ç –®–∞–Ω—Ü–µ–≤.\\r\\n\\r\\n–£ –ù–∞—Ç–∞–ª—å–∏ –ö–∞–∑–∞—á–∫–æ–≤–æ–π (–∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞ –ø–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ) –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π —Å–ª—É–∂–±—ã –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è. –£ –µ–µ –±–ª–æ–∫–∞ –ø—Ä–µ–∂–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ - —É–ª—É—á—à–µ–Ω–∏–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∫–ª–∏–º–∞—Ç–∞, –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π, —Å–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç, –Ω–æ –≤ —Å–≤—è–∑–∫–µ —Å–æ —Å–ª—É–∂–±–æ–π –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ —ç—Ç–∞ —Ä–∞–±–æ—Ç–∞ –¥–æ–ª–∂–Ω–∞ —Å—Ç–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π. –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º –í–ª–∞–¥–∏–º–∏—Ä–æ–º –ü—É—Ç–∏–Ω—ã–º –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –≤ —Å—Ç—Ä–∞–Ω–µ 25 –º–ª–Ω. —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç. –í–∞–∂–Ω–æ, –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É—è—Å—å –Ω–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞ —Ç—Ä—É–¥–∞ –∫–∞–∂–¥–æ–≥–æ –º—É–Ω–∏—Ü–∏–ø–∞–ª–∏—Ç–µ—Ç–∞, –ø—Ä–∏–≤–æ–¥–∏—Ç—å –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ —Ç—É–¥–∞, –≥–¥–µ –æ–Ω–∏ –Ω–µ –±—É–¥—É—Ç –∏—Å–ø—ã—Ç—ã–≤–∞—Ç—å –¥–µ—Ñ–∏—Ü–∏—Ç–∞ –≤ –∫–∞–¥—Ä–∞—Ö, –≥–¥–µ –µ—Å—Ç—å —Å–≤–æ–±–æ–¥–Ω–∞—è —Ä–∞–±–æ—á–∞—è —Å–∏–ª–∞. –ê —Ç–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, —á—Ç–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è –≤ –ù–∏–∂–Ω–µ–º, –î–∑–µ—Ä–∂–∏–Ω—Å–∫–µ, –ö—Å—Ç–æ–≤–æ –ù—É–∂–Ω–æ –Ω–∞–ª–∞–∂–∏–≤–∞—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –º–µ–∂–¥—É –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–º –∏ –≤—Å–µ–º–∏ —Ä–∞–π–æ–Ω–∞–º–∏. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–º–ø–ª–µ–∫—Å –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –Ω–æ–≤—ã—Ö —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç\",- –ø—Ä–æ–¥–æ–ª–∂–∏–ª –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä.\\r\\n\\r\\n\"–ê–Ω—Ç–æ–Ω—É –ê–≤–µ—Ä–∏–Ω—É (–∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞) –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é –ø–æ—Ä—É—á–∏—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º –±–ª–æ–∫–æ–º. –í–º–µ—Å—Ç–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã—Ö –¥–æ—Ä–æ–≥ —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤–æ–µ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ - —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –∏ –∞–≤—Ç–æ–¥–æ—Ä–æ–≥. –ü–æ—è–≤–∏–ª—Å—è –î–æ—Ä–æ–∂–Ω—ã–π —Ñ–æ–Ω–¥, –≤ —ç—Ç–æ–º –≥–æ–¥—É –æ–Ω —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 10 –º–ª—Ä–¥ —Ä—É–±–ª–µ–π - —Å–µ—Ä—å–µ–∑–Ω–æ–µ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø–æ—ç—Ç–æ–º—É –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–µ—Ä—å–µ–∑–Ω–∞—è —Ä–∞–±–æ—Ç–∞. –ó–∞–¥–∞—á–∞–º–∏ —Å—á–∏—Ç–∞—é —É—Å–∫–æ—Ä–µ–Ω–∏–µ —Ç–µ–º–ø–æ–≤ —Ä–µ–º–æ–Ω—Ç–∞ –∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –¥–æ—Ä–æ–≥, –∞ —Ç–∞–∫–∂–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç–µ–º–ø–æ–≤ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –∂–∏–ª—å—è. –ü—Ä–∏ —ç—Ç–æ–º —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é, —á—Ç–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤ –æ–¥–Ω–æ–º –±–ª–æ–∫–µ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ –ñ–ö–• –∏ —Ç–æ–ø–ª–∏–≤–Ω–æ-—ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–º–ø–ª–µ–∫—Å–∞ –∏ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –±—É–¥–µ—Ç —Å–ø–æ—Å–æ–±—Å—Ç–≤–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∑–µ–º–µ–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–∫–æ–≤ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã\", - –æ—Ç–º–µ—Ç–∏–ª –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä.\\r\\n\\r\\n–ü–æ –µ–≥–æ —Å–ª–æ–≤–∞–º, –≤ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–º –±–ª–æ–∫–µ —É –î–º–∏—Ç—Ä–∏—è –°–≤–∞—Ç–∫–æ–≤—Å–∫–æ–≥–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ, –Ω–æ –≤–∞–∂–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Å–æ—Ö—Ä–∞–Ω—ã –æ–±—ä–µ–∫—Ç–æ–≤ –∫—É–ª—å—Ç—É—Ä–Ω–æ–≥–æ –Ω–∞—Å–ª–µ–¥–∏—è: \"–†–∞–Ω—å—à–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ–º –∏ –æ—Ö—Ä–∞–Ω–æ–π –∑–∞–Ω–∏–º–∞–ª—Å—è –æ–¥–∏–Ω –±–ª–æ–∫, –Ω–µ—Ä–µ–¥–∫–æ –≤–æ–∑–Ω–∏–∫–∞–ª–∏ –≤–æ–ø—Ä–æ—Å—ã. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–æ—Å–æ—Ö—Ä–∞–Ω–∫—É–ª—å—Ç—É—Ä—ã –¥–æ–ª–∂–Ω–æ –≤—ã—Å—Ç—É–ø–∞—Ç—å –∫–∞–∫ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä, –Ω–µ –ø–æ–¥—á–∏–Ω—è—é—â–∏–π—Å—è —Ç–µ–º, –∫—Ç–æ —Å—Ç—Ä–æ–∏—Ç –∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç\".\\r\\n\\r\\n\"–ò –µ—â–µ –æ–¥–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ. –í –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤ —Å—Ç—Ä–∞–Ω–µ –∏ —É –Ω–∞—Å –≤ —Ä–µ–≥–∏–æ–Ω–µ –¥–µ–ª–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –±–æ—Ä—å–±—É —Å –∫–æ—Ä—Ä—É–ø—Ü–∏–µ–π, –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫—É—é, –∞–Ω—Ç–∏–Ω–∞—Ä–∫–æ—Ç–∏—á–µ—Å–∫—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –°–æ–∑–¥–∞–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–∏—Å—Å–∏–∏, —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –æ—á–µ–Ω—å –º–∞—Å—à—Ç–∞–±–Ω—ã –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã. –°—á–∏—Ç–∞—é, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –±—ã –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ –≥–æ—Ç–æ–≤–∏–ª —ç—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã - –æ–±—ä–µ–º —Ä–∞–±–æ—Ç—ã –ø–æ –Ω–∏–º –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π. –ü—Ä–∏–Ω—è–ª —Ä–µ—à–µ–Ω–∏–µ, —á—Ç–æ –¥–∞–Ω–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ —Å—Ç–∞—Ç—É—Å–µ –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞ –±—É–¥–µ—Ç –∫—É—Ä–∏—Ä–æ–≤–∞—Ç—å –í–∞–ª–µ—Ä–∏–π –ù–∞–∑–∞—Ä–æ–≤, - —Å–æ–æ–±—â–∞–µ—Ç –®–∞–Ω—Ü–µ–≤. - –≠—Ç–æ —Å–µ—Ä—å–µ–∑–Ω—ã–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª —Å –±–æ–ª—å—à–∏–º –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≤ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö, –±–æ–ª–µ–µ —Ç—Ä–µ—Ö –ª–µ—Ç –≤–æ–∑–≥–ª–∞–≤–ª—è–ª –£–§–°–ë –ø–æ –ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏, —è–≤–ª—è–ª—Å—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º –£–§–°–ë –≤ –û—Ä–ª–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏. –û–Ω –≤–æ–∑—å–º–µ—Ç –Ω–∞ —Å–µ–±—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—é —Å –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ—Ä–≥–∞–Ω–∞–º–∏, –∑–∞–∫–æ–Ω–æ—Ç–≤–æ—Ä—á–µ—Å–∫—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–∏—Ä–æ–≤—ã—Ö —Å—É–¥–µ–π, –∞–¥–≤–æ–∫–∞—Ç—É—Ä—ã –∏ –Ω–æ—Ç–∞—Ä–∏–∞—Ç–∞, –∞ —Ç–∞–∫–∂–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π —Ä–∞–±–æ—Ç—ã –∫–æ–º–∏—Å—Å–∏–π –ø—Ä–∏ –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–µ - –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–π, –∞–Ω—Ç–∏–Ω–∞—Ä–∫–æ—Ç–∏—á–µ—Å–∫–æ–π, –∞–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–æ–π\". –í –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –®–∞–Ω—Ü–µ–≤ –≤—ã—Ä–∞–∑–∏–ª –Ω–∞–¥–µ–∂–¥—É –Ω–∞ —Ç–æ, —á—Ç–æ –≤—Å–µ –±–ª–æ–∫–∏ –æ–±–ª–∞—Å—Ç–Ω–æ–≥–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ.\\r\\n',\n",
              "    spans=[Ne5Span(\n",
              "         index='T1',\n",
              "         type='PER',\n",
              "         start=2,\n",
              "         stop=8,\n",
              "         text='–®–∞–Ω—Ü–µ–≤'\n",
              "     ), Ne5Span(\n",
              "         index='T2',\n",
              "         type='PER',\n",
              "         start=112,\n",
              "         stop=126,\n",
              "         text='–í–∞–ª–µ—Ä–∏–π –®–∞–Ω—Ü–µ–≤'\n",
              "     ), Ne5Span(\n",
              "         index='T3',\n",
              "         type='LOC',\n",
              "         start=174,\n",
              "         stop=195,\n",
              "         text='–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏'\n",
              "     ), Ne5Span(\n",
              "         index='T4',\n",
              "         type='PER',\n",
              "         start=210,\n",
              "         stop=216,\n",
              "         text='–®–∞–Ω—Ü–µ–≤'\n",
              "     ), Ne5Span(\n",
              "         index='T5',\n",
              "         type='PER',\n",
              "         start=797,\n",
              "         stop=814,\n",
              "         text='–í–ª–∞–¥–∏–º–∏—Ä–∞ –ò–≤–∞–Ω–æ–≤–∞'\n",
              "     ), Ne5Span(\n",
              "         index='T6',\n",
              "         type='LOC',\n",
              "         start=832,\n",
              "         stop=853,\n",
              "         text='–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏'\n",
              "     ), Ne5Span(\n",
              "         index='T7',\n",
              "         type='PER',\n",
              "         start=1230,\n",
              "         stop=1244,\n",
              "         text='–ï–≤–≥–µ–Ω–∏—è –õ—é–ª–∏–Ω–∞'\n",
              "     ), Ne5Span(\n",
              "         index='T8',\n",
              "         type='ORG',\n",
              "         start=1267,\n",
              "         stop=1290,\n",
              "         text='–û–û–û \"–õ–£–ö–û–ô–õ-–≠–Ω–µ—Ä–≥–æ—Å–µ—Ç–∏\"'\n",
              "     ), Ne5Span(\n",
              "         index='T9',\n",
              "         type='ORG',\n",
              "         start=1309,\n",
              "         stop=1334,\n",
              "         text='–ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è'\n",
              "     ), Ne5Span(\n",
              "         index='T10',\n",
              "         type='LOC',\n",
              "         start=1335,\n",
              "         stop=1348,\n",
              "         text='–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π'\n",
              "     ), Ne5Span(\n",
              "         index='T11',\n",
              "         type='LOC',\n",
              "         start=1476,\n",
              "         stop=1497,\n",
              "         text='–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫—É—é –æ–±–ª–∞—Å—Ç—å'\n",
              "     ), Ne5Span(\n",
              "         index='T12',\n",
              "         type='PER',\n",
              "         start=1717,\n",
              "         stop=1723,\n",
              "         text='–®–∞–Ω—Ü–µ–≤'\n",
              "     ), Ne5Span(\n",
              "         index='T13',\n",
              "         type='PER',\n",
              "         start=1730,\n",
              "         stop=1748,\n",
              "         text='–ù–∞—Ç–∞–ª—å–∏ –ö–∞–∑–∞—á–∫–æ–≤–æ–π'\n",
              "     ), Ne5Span(\n",
              "         index='T14',\n",
              "         type='PER',\n",
              "         start=2091,\n",
              "         stop=2109,\n",
              "         text='–í–ª–∞–¥–∏–º–∏—Ä–æ–º –ü—É—Ç–∏–Ω—ã–º'\n",
              "     ), Ne5Span(\n",
              "         index='T15',\n",
              "         type='LOC',\n",
              "         start=2414,\n",
              "         stop=2420,\n",
              "         text='–ù–∏–∂–Ω–µ–º'\n",
              "     ), Ne5Span(\n",
              "         index='T16',\n",
              "         type='LOC',\n",
              "         start=2422,\n",
              "         stop=2432,\n",
              "         text='–î–∑–µ—Ä–∂–∏–Ω—Å–∫–µ'\n",
              "     ), Ne5Span(\n",
              "         index='T17',\n",
              "         type='LOC',\n",
              "         start=2434,\n",
              "         stop=2440,\n",
              "         text='–ö—Å—Ç–æ–≤–æ'\n",
              "     ), Ne5Span(\n",
              "         index='T18',\n",
              "         type='PER',\n",
              "         start=2586,\n",
              "         stop=2600,\n",
              "         text='–ê–Ω—Ç–æ–Ω—É –ê–≤–µ—Ä–∏–Ω—É'\n",
              "     ), Ne5Span(\n",
              "         index='T19',\n",
              "         type='ORG',\n",
              "         start=2814,\n",
              "         stop=2827,\n",
              "         text='–î–æ—Ä–æ–∂–Ω—ã–π —Ñ–æ–Ω–¥'\n",
              "     ), Ne5Span(\n",
              "         index='T20',\n",
              "         type='PER',\n",
              "         start=3355,\n",
              "         stop=3375,\n",
              "         text='–î–º–∏—Ç—Ä–∏—è –°–≤–∞—Ç–∫–æ–≤—Å–∫–æ–≥–æ'\n",
              "     ), Ne5Span(\n",
              "         index='T21',\n",
              "         type='PER',\n",
              "         start=4142,\n",
              "         stop=4157,\n",
              "         text='–í–∞–ª–µ—Ä–∏–π –ù–∞–∑–∞—Ä–æ–≤'\n",
              "     ), Ne5Span(\n",
              "         index='T22',\n",
              "         type='PER',\n",
              "         start=4170,\n",
              "         stop=4176,\n",
              "         text='–®–∞–Ω—Ü–µ–≤'\n",
              "     ), Ne5Span(\n",
              "         index='T23',\n",
              "         type='ORG',\n",
              "         start=4290,\n",
              "         stop=4294,\n",
              "         text='–£–§–°–ë'\n",
              "     ), Ne5Span(\n",
              "         index='T24',\n",
              "         type='LOC',\n",
              "         start=4298,\n",
              "         stop=4319,\n",
              "         text='–ù–∏–∂–µ–≥–æ—Ä–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏'\n",
              "     ), Ne5Span(\n",
              "         index='T25',\n",
              "         type='ORG',\n",
              "         start=4343,\n",
              "         stop=4347,\n",
              "         text='–£–§–°–ë'\n",
              "     ), Ne5Span(\n",
              "         index='T26',\n",
              "         type='LOC',\n",
              "         start=4350,\n",
              "         stop=4367,\n",
              "         text='–û—Ä–ª–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏'\n",
              "     ), Ne5Span(\n",
              "         index='T27',\n",
              "         type='PER',\n",
              "         start=4667,\n",
              "         stop=4673,\n",
              "         text='–®–∞–Ω—Ü–µ–≤'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**NLTK**"
      ],
      "metadata": {
        "id": "QusHvb6qM-7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = next(load_ne5(path)).text"
      ],
      "metadata": {
        "id": "t4DB5orJGeml"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sV4-WwdSKfFf",
        "outputId": "9eebc44f-e172-4219-b9f3-e2c59ce334c0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º \"–ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ\" –Ω–∞–∑–Ω–∞—á–µ–Ω –Æ.–Ø–º–ø–æ–ª—å—Å–∫–∏–π.\\r\\n\\r\\n06.03.2012, –ú–æ—Å–∫–≤–∞ 19:41:19 –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º –û–û–û \"–ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ\" (–≤—Ö–æ–¥–∏—Ç –≤ –≥—Ä—É–ø–ø—É \"–ú–µ—á–µ–ª\") –Ω–∞–∑–Ω–∞—á–µ–Ω –Æ—Ä–∏–π –Ø–º–ø–æ–ª—å—Å–∫–∏–π, –∫–æ—Ç–æ—Ä—ã–π —Å–º–µ–Ω–∏–ª –Ω–∞ —ç—Ç–æ–º –ø–æ—Å—Ç—É –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ê–Ω–∞—Ç–æ–ª–∏—è –ß–µ—Ä–Ω–∞–∫–æ–≤–∞. –û–± —ç—Ç–æ–º –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏. –ù–æ–≤—ã–π –≥–ª–∞–≤–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –±—É–¥–µ—Ç —É–ø—Ä–∞–≤–ª—è—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∏–º–∏ –∏ —ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç–æ–≤—ã–º–∏ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è–º–∏, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –∏—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.\\r\\n\\r\\n–ö–∞–∫ –æ—Ç–º–µ—á–∞–µ—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏, –Æ.–Ø–º–ø–æ–ª—å—Å–∫–∏–π –∏–º–µ–µ—Ç –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –≤ —Å—Ñ–µ—Ä–µ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏, —Å –Ω–æ—è–±—Ä—è 2010–≥. –∏ –¥–æ –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–Ω –∑–∞–Ω–∏–º–∞–ª –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ø–æ —ç–∫–æ–Ω–æ–º–∏–∫–µ –∏ —Ñ–∏–Ω–∞–Ω—Å–∞–º, –ø–µ—Ä–≤–æ–≥–æ –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –û–ê–û \"–ù–∞—É—á–Ω–æ-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä –º–µ–∂—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π\", —Å 1997–≥. –∑–∞–Ω–∏–º–∞–ª —Ä—É–∫–æ–≤–æ–¥—è—â–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏.\\r\\n\\r\\n\"–ú–µ—á–µ–ª\" –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π —É–≥–ª—è, –∂–µ–ª–µ–∑–æ—Ä—É–¥–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–∞, —Å—Ç–∞–ª–∏, –ø—Ä–æ–∫–∞—Ç–∞, —Ñ–µ—Ä—Ä–æ—Å–ø–ª–∞–≤–æ–≤, –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –≤—ã—Å–æ–∫–∏—Ö –ø–µ—Ä–µ–¥–µ–ª–æ–≤, —Ç–µ–ø–ª–æ–≤–æ–π –∏ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–æ–π —ç–Ω–µ—Ä–≥–∏–∏. –ë–∏–∑–Ω–µ—Å \"–ú–µ—á–µ–ª–∞\" —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: –≥–æ—Ä–Ω–æ–¥–æ–±—ã–≤–∞—é—â–µ–≥–æ, –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—á–µ—Å–∫–æ–≥–æ, —Ñ–µ—Ä—Ä–æ—Å–ø–ª–∞–≤–Ω–æ–≥–æ –∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ. –ì—Ä—É–ø–ø–∞ \"–ú–µ—á–µ–ª\" –≤ 2011–≥. —É–≤–µ–ª–∏—á–∏–ª–∞ –≤—ã–ø—É—Å–∫ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–∞ –∫–æ–∫—Å—É—é—â–µ–≥–æ—Å—è —É–≥–ª—è –Ω–∞ 9% - –¥–æ 12,5 –º–ª–Ω —Ç, –≤—ã–ø—É—Å–∫ —Å—Ç–∞–ª–∏ - –Ω–∞ 1% - –¥–æ 6 –º–ª–Ω 118 —Ç—ã—Å. —Ç. –û—Å–Ω–æ–≤–Ω—ã–º –±–µ–Ω–µ—Ñ–∏—Ü–∏–∞—Ä–æ–º –û–ê–û \"–ú–µ—á–µ–ª\" —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –≥—Ä—É–ø–ø—ã –ò.–ó—é–∑–∏–Ω, free float (ADR) —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–∫–æ–ª–æ 30%. –ß–∏—Å—Ç—ã–π —É–±—ã—Ç–æ–∫ –û–ê–û \"–ú–µ—á–µ–ª\" –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–≥–æ —É—á–µ—Ç–∞ (–†–°–ë–£) –∑–∞ 2011–≥. —Å–æ—Å—Ç–∞–≤–∏–ª 19,674 –º–ª—Ä–¥ —Ä—É–±. –ø—Ä–æ—Ç–∏–≤ –ø—Ä–∏–±—ã–ª–∏ –≤ 42,929 –º–ª—Ä–¥ —Ä—É–±. –≤ 2010–≥. –í—ã—Ä—É—á–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞—Å—å –≤ 5,6 —Ä–∞–∑–∞ - –¥–æ 8,514 –º–ª—Ä–¥ —Ä—É–±., –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 7,703 –º–ª—Ä–¥ —Ä—É–±. (—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –≤ 5,2 —Ä–∞–∑–∞).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrZ5KdlbJUxS",
        "outputId": "0d26bb5c-13ec-426e-c270-9e954943d26a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('ADR', 'ORGANIZATION'),\n",
              " ('–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º', 'GPE'),\n",
              " ('–û–ê–û', 'ORGANIZATION'),\n",
              " ('–û—Å–Ω–æ–≤–Ω—ã–º', 'ORGANIZATION'),\n",
              " ('–†–°–ë–£', 'ORGANIZATION')}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**SPACY**"
      ],
      "metadata": {
        "id": "bAmCiJs7NbgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVN9InovM9Hq",
        "outputId": "1b1b2321-93ab-450b-d445-171fb74be6dd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsDDitulNyBd",
        "outputId": "e9d6d1e0-ec63-42ce-9e31-728550cd0485"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-27 11:39:54.909385: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ru-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.4.0/ru_core_news_sm-3.4.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.3 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymorphy2>=0.9 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.4.0) (3.4.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: ru-core-news-sm\n",
            "Successfully installed ru-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "Quuk2a65OIFX"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('ru_core_news_sm')"
      ],
      "metadata": {
        "id": "uE63K3MpOVeE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ny_bb = document\n",
        "article = nlp(ny_bb)\n",
        "displacy.render(article, jupyter=True, style='ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B7tK4yCsOaQa",
        "outputId": "90f8d8d9-6301-477a-9938-e8b309e5d0ff"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º &quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; –Ω–∞–∑–Ω–∞—á–µ–Ω \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –Æ.–Ø–º–ø–æ–ª—å—Å–∫–∏–π\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ".\r</br>\r</br>06.03.2012, \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ú–æ—Å–∫–≤–∞\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " 19:41:19 –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –û–û–û &quot;–ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ&quot;\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " (–≤—Ö–æ–¥–∏—Ç –≤ –≥—Ä—É–ø–ø—É &quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ú–µ—á–µ–ª\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot;) –Ω–∞–∑–Ω–∞—á–µ–Ω \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –Æ—Ä–∏–π –Ø–º–ø–æ–ª—å—Å–∫–∏–π\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", –∫–æ—Ç–æ—Ä—ã–π —Å–º–µ–Ω–∏–ª –Ω–∞ —ç—Ç–æ–º –ø–æ—Å—Ç—É –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ê–Ω–∞—Ç–æ–ª–∏—è –ß–µ—Ä–Ω–∞–∫–æ–≤–∞\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". –û–± —ç—Ç–æ–º –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏. –ù–æ–≤—ã–π –≥–ª–∞–≤–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –±—É–¥–µ—Ç —É–ø—Ä–∞–≤–ª—è—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∏–º–∏ –∏ —ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç–æ–≤—ã–º–∏ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è–º–∏, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –∏—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.\r</br>\r</br>–ö–∞–∫ –æ—Ç–º–µ—á–∞–µ—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏, \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –Æ.–Ø–º–ø–æ–ª—å—Å–∫–∏–π\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " –∏–º–µ–µ—Ç –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –≤ —Å—Ñ–µ—Ä–µ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏, —Å –Ω–æ—è–±—Ä—è 2010–≥. –∏ –¥–æ –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–Ω –∑–∞–Ω–∏–º–∞–ª –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ø–æ —ç–∫–æ–Ω–æ–º–∏–∫–µ –∏ —Ñ–∏–Ω–∞–Ω—Å–∞–º, –ø–µ—Ä–≤–æ–≥–æ –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –û–ê–û &quot;–ù–∞—É—á–Ω–æ-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä –º–µ–∂—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π&quot;\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", —Å 1997–≥. –∑–∞–Ω–∏–º–∞–ª —Ä—É–∫–æ–≤–æ–¥—è—â–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏.\r</br>\r</br>&quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ú–µ—á–µ–ª\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π —É–≥–ª—è, –∂–µ–ª–µ–∑–æ—Ä—É–¥–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–∞, —Å—Ç–∞–ª–∏, –ø—Ä–æ–∫–∞—Ç–∞, —Ñ–µ—Ä—Ä–æ—Å–ø–ª–∞–≤–æ–≤, –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –≤—ã—Å–æ–∫–∏—Ö –ø–µ—Ä–µ–¥–µ–ª–æ–≤, —Ç–µ–ø–ª–æ–≤–æ–π –∏ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–æ–π —ç–Ω–µ—Ä–≥–∏–∏. –ë–∏–∑–Ω–µ—Å &quot;–ú–µ—á–µ–ª–∞&quot; —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: –≥–æ—Ä–Ω–æ–¥–æ–±—ã–≤–∞—é—â–µ–≥–æ, –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—á–µ—Å–∫–æ–≥–æ, —Ñ–µ—Ä—Ä–æ—Å–ø–ª–∞–≤–Ω–æ–≥–æ –∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ. –ì—Ä—É–ø–ø–∞ &quot;\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ú–µ—á–µ–ª\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "&quot; –≤ 2011–≥. —É–≤–µ–ª–∏—á–∏–ª–∞ –≤—ã–ø—É—Å–∫ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–∞ –∫–æ–∫—Å—É—é—â–µ–≥–æ—Å—è —É–≥–ª—è –Ω–∞ 9% - –¥–æ 12,5 –º–ª–Ω —Ç, –≤—ã–ø—É—Å–∫ —Å—Ç–∞–ª–∏ - –Ω–∞ 1% - –¥–æ 6 –º–ª–Ω 118 —Ç—ã—Å. —Ç. –û—Å–Ω–æ–≤–Ω—ã–º –±–µ–Ω–µ—Ñ–∏—Ü–∏–∞—Ä–æ–º \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –û–ê–û &quot;–ú–µ—á–µ–ª&quot;\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –≥—Ä—É–ø–ø—ã \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –ò.–ó—é–∑–∏–Ω\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", free float (ADR) —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–∫–æ–ª–æ 30%. –ß–∏—Å—Ç—ã–π —É–±—ã—Ç–æ–∫ \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –û–ê–û &quot;–ú–µ—á–µ–ª&quot;\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–≥–æ —É—á–µ—Ç–∞ (–†–°–ë–£) –∑–∞ 2011–≥. —Å–æ—Å—Ç–∞–≤–∏–ª 19,674 –º–ª—Ä–¥ —Ä—É–±. –ø—Ä–æ—Ç–∏–≤ –ø—Ä–∏–±—ã–ª–∏ –≤ 42,929 –º–ª—Ä–¥ —Ä—É–±. –≤ 2010–≥. \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    –í—ã—Ä—É—á–∫–∞\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " –∫–æ–º–ø–∞–Ω–∏–∏ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞—Å—å –≤ 5,6 —Ä–∞–∑–∞ - –¥–æ 8,514 –º–ª—Ä–¥ —Ä—É–±., –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 7,703 –º–ª—Ä–¥ —Ä—É–±. (—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –≤ 5,2 —Ä–∞–∑–∞).</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ3H_HUoZG-w",
        "outputId": "2220c450-5555-4a97-d7a2-94b200a07812"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º \"–ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ\" –Ω–∞–∑–Ω–∞—á–µ–Ω –Æ.–Ø–º–ø–æ–ª—å—Å–∫–∏–π.\n",
              "\n",
              "06.03.2012, –ú–æ—Å–∫–≤–∞ 19:41:19 –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º –û–û–û \"–ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ\" (–≤—Ö–æ–¥–∏—Ç –≤ –≥—Ä—É–ø–ø—É \"–ú–µ—á–µ–ª\") –Ω–∞–∑–Ω–∞—á–µ–Ω –Æ—Ä–∏–π –Ø–º–ø–æ–ª—å—Å–∫–∏–π, –∫–æ—Ç–æ—Ä—ã–π —Å–º–µ–Ω–∏–ª –Ω–∞ —ç—Ç–æ–º –ø–æ—Å—Ç—É –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ê–Ω–∞—Ç–æ–ª–∏—è –ß–µ—Ä–Ω–∞–∫–æ–≤–∞. –û–± —ç—Ç–æ–º –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏. –ù–æ–≤—ã–π –≥–ª–∞–≤–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –±—É–¥–µ—Ç —É–ø—Ä–∞–≤–ª—è—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∏–º–∏ –∏ —ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç–æ–≤—ã–º–∏ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è–º–∏, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –∏—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.\n",
              "\n",
              "–ö–∞–∫ –æ—Ç–º–µ—á–∞–µ—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏, –Æ.–Ø–º–ø–æ–ª—å—Å–∫–∏–π –∏–º–µ–µ—Ç –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –≤ —Å—Ñ–µ—Ä–µ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏, —Å –Ω–æ—è–±—Ä—è 2010–≥. –∏ –¥–æ –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–Ω –∑–∞–Ω–∏–º–∞–ª –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ø–æ —ç–∫–æ–Ω–æ–º–∏–∫–µ –∏ —Ñ–∏–Ω–∞–Ω—Å–∞–º, –ø–µ—Ä–≤–æ–≥–æ –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –û–ê–û \"–ù–∞—É—á–Ω–æ-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä –º–µ–∂—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π\", —Å 1997–≥. –∑–∞–Ω–∏–º–∞–ª —Ä—É–∫–æ–≤–æ–¥—è—â–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏.\n",
              "\n",
              "\"–ú–µ—á–µ–ª\" –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π —É–≥–ª—è, –∂–µ–ª–µ–∑–æ—Ä—É–¥–Ω–æ–≥–æ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–∞, —Å—Ç–∞–ª–∏, –ø—Ä–æ–∫–∞—Ç–∞, —Ñ–µ—Ä—Ä–æ—Å–ø–ª–∞–≤–æ–≤, –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –≤—ã—Å–æ–∫–∏—Ö –ø–µ—Ä–µ–¥–µ–ª–æ–≤, —Ç–µ–ø–ª–æ–≤–æ–π –∏ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–æ–π —ç–Ω–µ—Ä–≥–∏–∏. –ë–∏–∑–Ω–µ—Å \"–ú–µ—á–µ–ª–∞\" —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: –≥–æ—Ä–Ω–æ–¥–æ–±—ã–≤–∞—é—â–µ–≥–æ, –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—á–µ—Å–∫–æ–≥–æ, —Ñ–µ—Ä—Ä–æ—Å–ø–ª–∞–≤–Ω–æ–≥–æ –∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ. –ì—Ä—É–ø–ø–∞ \"–ú–µ—á–µ–ª\" –≤ 2011–≥. —É–≤–µ–ª–∏—á–∏–ª–∞ –≤—ã–ø—É—Å–∫ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ç–∞ –∫–æ–∫—Å—É—é—â–µ–≥–æ—Å—è —É–≥–ª—è –Ω–∞ 9% - –¥–æ 12,5 –º–ª–Ω —Ç, –≤—ã–ø—É—Å–∫ —Å—Ç–∞–ª–∏ - –Ω–∞ 1% - –¥–æ 6 –º–ª–Ω 118 —Ç—ã—Å. —Ç. –û—Å–Ω–æ–≤–Ω—ã–º –±–µ–Ω–µ—Ñ–∏—Ü–∏–∞—Ä–æ–º –û–ê–û \"–ú–µ—á–µ–ª\" —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –≥—Ä—É–ø–ø—ã –ò.–ó—é–∑–∏–Ω, free float (ADR) —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–∫–æ–ª–æ 30%. –ß–∏—Å—Ç—ã–π —É–±—ã—Ç–æ–∫ –û–ê–û \"–ú–µ—á–µ–ª\" –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–≥–æ —É—á–µ—Ç–∞ (–†–°–ë–£) –∑–∞ 2011–≥. —Å–æ—Å—Ç–∞–≤–∏–ª 19,674 –º–ª—Ä–¥ —Ä—É–±. –ø—Ä–æ—Ç–∏–≤ –ø—Ä–∏–±—ã–ª–∏ –≤ 42,929 –º–ª—Ä–¥ —Ä—É–±. –≤ 2010–≥. –í—ã—Ä—É—á–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞—Å—å –≤ 5,6 —Ä–∞–∑–∞ - –¥–æ 8,514 –º–ª—Ä–¥ —Ä—É–±., –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 7,703 –º–ª—Ä–¥ —Ä—É–±. (—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –≤ 5,2 —Ä–∞–∑–∞)."
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TF NER**"
      ],
      "metadata": {
        "id": "KBPgis-DSkDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(load_ne5(path)):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)"
      ],
      "metadata": {
        "id": "fjeKY_b8S0FA"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
      ],
      "metadata": {
        "id": "MCWOJOxHS-0s"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words['tag'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euucMGGbS_5J",
        "outputId": "8daadc0e-9ed2-447d-bf2e-73e9eebf6b1a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OUT         219214\n",
              "PER          21200\n",
              "ORG          13651\n",
              "LOC           4568\n",
              "GEOPOLIT      4356\n",
              "MEDIA         2482\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_words.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LmEYSeHTTB3a",
        "outputId": "d956ea93-de85-4bc2-aa6f-42d6cacace33"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           word  tag\n",
              "0   –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º  OUT\n",
              "1    –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º  OUT\n",
              "2             \"  OUT\n",
              "3  –ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ  ORG\n",
              "4             \"  OUT\n",
              "5      –Ω–∞–∑–Ω–∞—á–µ–Ω  OUT\n",
              "6             –Æ  PER\n",
              "7             .  PER\n",
              "8    –Ø–º–ø–æ–ª—å—Å–∫–∏–π  PER\n",
              "9             .  OUT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6e7b199-8f4d-4fe2-a2f5-604a8f888161\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>–ú–µ—á–µ–ª-–≠–Ω–µ—Ä–≥–æ</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>–Ω–∞–∑–Ω–∞—á–µ–Ω</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>–Æ</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>.</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>–Ø–º–ø–æ–ª—å—Å–∫–∏–π</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6e7b199-8f4d-4fe2-a2f5-604a8f888161')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6e7b199-8f4d-4fe2-a2f5-604a8f888161 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6e7b199-8f4d-4fe2-a2f5-604a8f888161');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "FpE1QfNVTfO_"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
        "\n",
        "# labelEncode —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "metadata": {
        "id": "xa9dc-2uTgZw"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "\n",
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)"
      ],
      "metadata": {
        "id": "WlIgCK2aTrJb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "rIhUIynWUArk"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    #ngrams=(1, 3),\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "wv0LlAmBUBcN"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectorize_layer.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDBWYbdGUHyn",
        "outputId": "c0f24bc8-cfed-4f1d-9145-c99de8d4c558"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29927"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "class modelNER(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(modelNER, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim)\n",
        "        self.gPool = GlobalMaxPooling1D()\n",
        "        self.fc1 = Dense(300, activation='relu')\n",
        "        self.fc2 = Dense(50, activation='relu')\n",
        "        self.fc3 = Dense(6, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        pool_x = self.gPool(x)\n",
        "        \n",
        "        fc_x = self.fc1(pool_x)\n",
        "        fc_x = self.fc2(fc_x)\n",
        "        \n",
        "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
        "        prob = self.fc3(concat_x)\n",
        "        return prob"
      ],
      "metadata": {
        "id": "hbvDGUZCUKTg"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()"
      ],
      "metadata": {
        "id": "AnvhGLweUOHm"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bC0BaT6dUQCU"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXtAJe_fUSm4",
        "outputId": "16491279-2d18-4d1b-8844-eb3388c5741c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12444/12444 [==============================] - 302s 24ms/step - loss: 0.2960 - accuracy: 0.9137 - val_loss: 0.2138 - val_accuracy: 0.9370\n",
            "Epoch 2/3\n",
            "12444/12444 [==============================] - 297s 24ms/step - loss: 0.1265 - accuracy: 0.9625 - val_loss: 0.2222 - val_accuracy: 0.9400\n",
            "Epoch 3/3\n",
            "12444/12444 [==============================] - 307s 25ms/step - loss: 0.1100 - accuracy: 0.9653 - val_loss: 0.2746 - val_accuracy: 0.9402\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc8bb30690>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = mmodel.predict(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxVmM1gFiBND",
        "outputId": "9121aba8-4b74-4a4c-a1de-aba2f32376b3"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4148/4148 [==============================] - 7s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = np.array([np.argmax(x) for x in pred])"
      ],
      "metadata": {
        "id": "dA2a8uUoppIx"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(valid_y, np.array(pred_y))\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnRr14xho5El",
        "outputId": "b511e21f-f1ee-4f54-91b7-8379430dd2b8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89      1086\n",
            "           1       0.86      0.79      0.83      1189\n",
            "           2       0.92      0.77      0.84       615\n",
            "           3       0.88      0.55      0.68      3407\n",
            "           4       0.94      0.99      0.97     54793\n",
            "           5       0.99      0.69      0.82      5278\n",
            "\n",
            "    accuracy                           0.94     66368\n",
            "   macro avg       0.91      0.78      0.84     66368\n",
            "weighted avg       0.94      0.94      0.94     66368\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    ngrams=(1, 3),\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "y-HUm72LqWvt"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()"
      ],
      "metadata": {
        "id": "zFkYf74dqhOX"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v1reoQYkqj3U"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdeLKJibqnef",
        "outputId": "5d9c4f1f-ee51-448f-e240-5636b98796b6"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12444/12444 [==============================] - 306s 24ms/step - loss: 0.2929 - accuracy: 0.9146 - val_loss: 0.2121 - val_accuracy: 0.9367\n",
            "Epoch 2/3\n",
            "12444/12444 [==============================] - 301s 24ms/step - loss: 0.1252 - accuracy: 0.9629 - val_loss: 0.2299 - val_accuracy: 0.9397\n",
            "Epoch 3/3\n",
            "12444/12444 [==============================] - 298s 24ms/step - loss: 0.1096 - accuracy: 0.9654 - val_loss: 0.2570 - val_accuracy: 0.9398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc89054dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = mmodel.predict(valid_data)\n",
        "pred_y = np.array([np.argmax(x) for x in pred])\n",
        "report = classification_report(valid_y, np.array(pred_y))\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--uuhNOMqr8-",
        "outputId": "691af1ba-0152-4a6b-bc02-4aaa02c47b8a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4148/4148 [==============================] - 7s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      1086\n",
            "           1       0.86      0.79      0.82      1189\n",
            "           2       0.91      0.77      0.83       615\n",
            "           3       0.88      0.55      0.68      3407\n",
            "           4       0.94      0.99      0.97     54793\n",
            "           5       0.99      0.69      0.81      5278\n",
            "\n",
            "    accuracy                           0.94     66368\n",
            "   macro avg       0.91      0.78      0.83     66368\n",
            "weighted avg       0.94      0.94      0.93     66368\n",
            "\n"
          ]
        }
      ]
    }
  ]
}